<!DOCTYPE html>
<html>
<head>
    <title>OpenAI Audio Test</title>
</head>
<body>
    <button id="startBtn">Start</button>
    <button id="stopBtn" disabled>Stop</button>
    <pre id="log"></pre>

<script>
// Simple energy-based voice activity detection
class SimpleVAD {
    constructor(threshold = 0.015) {
        this.threshold = threshold;
    }

    // Simple energy-based voice detection
    isVoiceActive(audioData) {
        // Calculate RMS (Root Mean Square) energy
        let sum = 0;
        for (let i = 0; i < audioData.length; i++) {
            sum += audioData[i] * audioData[i];
        }
        const rms = Math.sqrt(sum / audioData.length);
        return rms > this.threshold;
    }
}
class AudioTest {
    constructor() {
        this.ws = null;
        this.stream = null;
        this.audioContext = null;
        this.processor = null;
        this.startBtn = document.getElementById('startBtn');
        this.stopBtn = document.getElementById('stopBtn');
        this.log = document.getElementById('log');
        this.simpleVad = new SimpleVAD();
        this.silenceStart = null;
        this.silenceThreshold = 1000; // 1 second of silence to trigger end of turn
    }

    logMessage(msg) {
        // For console, log the full message
        console.log(msg);
        
        // For display, handle objects and truncate long string values
        let displayMsg;
        if (typeof msg === 'object') {
            // Deep clone to avoid modifying original
            const processedMsg = JSON.parse(JSON.stringify(msg));
            
            // Recursively process object values
            const truncateValues = (obj) => {
                for (let key in obj) {
                    if (typeof obj[key] === 'string' && obj[key].length > 100) {
                        obj[key] = obj[key].substring(0, 97) + '...';
                    } else if (typeof obj[key] === 'object' && obj[key] !== null) {
                        truncateValues(obj[key]);
                    }
                }
            };
            
            truncateValues(processedMsg);
            displayMsg = JSON.stringify(processedMsg, null, 2);
        } else {
            displayMsg = msg.toString();
            if (displayMsg.length > 100) {
                displayMsg = displayMsg.substring(0, 97) + '...';
            }
        }
        
        this.log.textContent += displayMsg + '\n';
        this.log.scrollTop = this.log.scrollHeight;
    }

    async start() {
        try {
            // Connect WebSocket
            this.ws = new WebSocket('ws://localhost:3000/ws');
            this.ws.onmessage = (e) => {
                let data;
                try {
                    data = JSON.parse(e.data);
                    this.logMessage({direction: '←', data});
                } catch {
                    this.logMessage('← Received: ' + e.data);
                }
            };
            this.ws.onopen = () => this.logMessage('WebSocket connected');
            this.ws.onclose = () => this.logMessage('WebSocket closed');
            this.ws.onerror = (e) => this.logMessage('WebSocket error: ' + e);

            // Get audio stream with specific constraints
            this.stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                    channelCount: 1,
                    sampleRate: 24000
                }
            });
            this.logMessage('Got audio stream');

            // Setup audio processing with analyzer
            this.audioContext = new AudioContext();
            const source = this.audioContext.createMediaStreamSource(this.stream);
            
            // Create analyzer for volume monitoring
            this.analyser = this.audioContext.createAnalyser();
            this.analyser.fftSize = 256;
            source.connect(this.analyser);
            
            this.processor = this.audioContext.createScriptProcessor(2048, 1, 1);
            
            this.processor.onaudioprocess = (e) => {
                if (this.ws.readyState === WebSocket.OPEN) {
                    const audioData = e.inputBuffer.getChannelData(0);
                    
                    // Check for voice activity using simple VAD
                    const isVoiceActive = this.simpleVad.isVoiceActive(audioData);
                    
                    // Get audio levels for logging
                    const array = new Uint8Array(this.analyser.frequencyBinCount);
                    this.analyser.getByteFrequencyData(array);
                    const average = array.reduce((a, b) => a + b) / array.length;
                    
                    // Handle silence detection
                    if (!isVoiceActive) {
                        if (this.silenceStart === null) {
                            this.silenceStart = Date.now();
                        } else if (Date.now() - this.silenceStart > this.silenceThreshold) {
                            this.sendEndOfTurn();
                            this.silenceStart = null;
                        }
                    } else {
                        this.silenceStart = null;
                    }
                    
                    if (isVoiceActive) {
                        // Convert Float32Array to Int16Array for PCM16 format
                        const pcm16Data = new Int16Array(audioData.length);
                        for (let i = 0; i < audioData.length; i++) {
                            // Convert float32 [-1.0, 1.0] to int16 [-32768, 32767]
                            const s = Math.max(-1, Math.min(1, audioData[i]));
                            pcm16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                        }
                        
                        // Convert to base64
                        const buffer = new ArrayBuffer(pcm16Data.length * 2);
                        new Int16Array(buffer).set(pcm16Data);
                        const base64Audio = btoa(
                            String.fromCharCode.apply(null, new Uint8Array(buffer))
                        );
                        
                        const message = {
                            type: "input_audio_buffer.append",
                            audio: base64Audio
                        };
                        const msgStr = JSON.stringify(message);
                        this.ws.send(msgStr);
                        this.logMessage({
                            direction: '→',
                            type: 'audio',
                            level: average.toFixed(2),
                            data: message
                        });
                    }
                }
            };

            source.connect(this.processor);
            this.processor.connect(this.audioContext.destination);
            
            this.startBtn.disabled = true;
            this.stopBtn.disabled = false;
            this.logMessage('Audio processing started');

        } catch (error) {
            this.logMessage('Error: ' + error);
        }
    }

    async stop() {
        if (this.stream) {
            this.stream.getTracks().forEach(track => track.stop());
            this.logMessage('Audio tracks stopped');
        }
        if (this.processor) {
            this.processor.disconnect();
            this.logMessage('Processor disconnected');
        }
        if (this.audioContext) {
            await this.audioContext.close();
            this.logMessage('Audio context closed');
        }
        if (this.ws) {
            this.ws.close();
            this.logMessage('WebSocket closed');
        }
        
        this.startBtn.disabled = false;
        this.stopBtn.disabled = true;
    }

    sendEndOfTurn() {
        if (this.ws && this.ws.readyState === WebSocket.OPEN) {
            // First commit the audio buffer
            const commitMessage = {
                type: "input_audio_buffer.commit"
            };
            this.ws.send(JSON.stringify(commitMessage));
            this.logMessage({
                direction: '→',
                type: 'control',
                data: commitMessage
            });

            // Then create a response
            const responseMessage = {
                type: "response.create"
            };
            this.ws.send(JSON.stringify(responseMessage));
            this.logMessage({
                direction: '→',
                type: 'control',
                data: responseMessage
            });
        }
    }
}

const test = new AudioTest();
startBtn.onclick = () => test.start();
stopBtn.onclick = () => test.stop();
</script>
</body>
</html>
